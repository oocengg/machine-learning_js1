{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NORMALISASI\n"
     ]
    }
   ],
   "source": [
    "print (\"NORMALISASI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_feature(data):\n",
    "    n_max = max(data)\n",
    "    n_min = min(data)\n",
    "    l_data  = len(data)\n",
    "    \n",
    "    for i in range (0,l_data):\n",
    "        data[i] = (data[i] - n_min) / (n_max - n_min)\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.375, 0.125, 0.5, 1.0]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [10, 25, 15, 30, 50]\n",
    "\n",
    "n_data = norm_feature(data)\n",
    "\n",
    "n_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensi dari data :\n",
      "(5, 2)\n",
      "Artinya 5 Baris, 2 Kolom\n"
     ]
    }
   ],
   "source": [
    "data1 = [\n",
    "    [100, 0.001],\n",
    "    [8, 0.05],\n",
    "    [50, 0.005],\n",
    "    [88, 0.07],\n",
    "    [4, 0.1]\n",
    "]\n",
    "\n",
    "np_data = np.asarray(data1)\n",
    "\n",
    "print (\"Dimensi dari data :\")\n",
    "\n",
    "print(np_data.shape)\n",
    "\n",
    "print (\"Artinya 5 Baris, 2 Kolom\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Asli :\n",
      "[[1.0e+02 1.0e-03]\n",
      " [8.0e+00 5.0e-02]\n",
      " [5.0e+01 5.0e-03]\n",
      " [8.8e+01 7.0e-02]\n",
      " [4.0e+00 1.0e-01]]\n",
      "\n",
      "Data Setelah Normalisasi :\n",
      "[[1.         0.        ]\n",
      " [0.04166667 0.49494949]\n",
      " [0.47916667 0.04040404]\n",
      " [0.875      0.6969697 ]\n",
      " [0.         1.        ]]\n"
     ]
    }
   ],
   "source": [
    "mm_scaler = MinMaxScaler()\n",
    "\n",
    "mm_data = mm_scaler.fit_transform(data1)\n",
    "\n",
    "print(\"Data Asli :\")\n",
    "print(np_data)\n",
    "print(\"\")\n",
    "print(\"Data Setelah Normalisasi :\")\n",
    "print(mm_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STANDARISASI\n"
     ]
    }
   ],
   "source": [
    "print (\"STANDARISASI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean, stdev\n",
    "\n",
    "def std_feature(data):\n",
    "    baris_data = data.shape[0]\n",
    "    kolom_data = data.shape[1]\n",
    "    \n",
    "    for i in range (0, baris_data):\n",
    "        for j in range (0,kolom_data):\n",
    "            data[i][j] = (data[i][j] - mean(data[:,j])) / stdev(data[:,j])\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.13053908, -1.04102352],\n",
       "       [-0.58585228,  0.43340554],\n",
       "       [ 0.54596936,  0.16378374],\n",
       "       [ 1.78715622,  0.2189989 ],\n",
       "       [ 1.53764773,  0.21485145]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2 = [\n",
    "    [100, 0.001],\n",
    "    [8, 0.05],\n",
    "    [50, 0.005],\n",
    "    [88, 0.07],\n",
    "    [4, 0.1]\n",
    "]\n",
    "\n",
    "np_data2 = np.asarray(data2)\n",
    "\n",
    "std_data = std_feature(np_data2)\n",
    "\n",
    "std_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Setelah Standarisasi :\n",
      "[[ 1.26398112 -1.16389967]\n",
      " [-1.06174414  0.12639634]\n",
      " [ 0.         -1.05856939]\n",
      " [ 0.96062565  0.65304778]\n",
      " [-1.16286263  1.44302493]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "ss_scaler = StandardScaler()\n",
    "\n",
    "std_data1 = ss_scaler.fit_transform(data2)\n",
    "\n",
    "print(\"Data Setelah Standarisasi :\")\n",
    "print(std_data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENCODING\n"
     ]
    }
   ],
   "source": [
    "print(\"ENCODING\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ordinal Encoding\n",
      "[[4.]\n",
      " [0.]\n",
      " [1.]\n",
      " [2.]\n",
      " [3.]]\n",
      "\n",
      "One Hot Encoding\n",
      "[[0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder,OneHotEncoder\n",
    "\n",
    "oe = [\n",
    "    ['POLINEMA'],\n",
    "    ['PENS'],\n",
    "    ['PNJ'],\n",
    "    ['PNP'],\n",
    "    ['POLBAN'],\n",
    "]\n",
    "\n",
    "ord_oe = OrdinalEncoder().fit_transform(oe)\n",
    "\n",
    "ohe_oe = OneHotEncoder().fit_transform(oe)\n",
    "\n",
    "print (\"Ordinal Encoding\")\n",
    "print(ord_oe)\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "print (\"One Hot Encoding\")\n",
    "print(ohe_oe.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF\n"
     ]
    }
   ],
   "source": [
    "print(\"TF-IDF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "            'the house had a tiny little mouse',\n",
    "            'the cat saw the mouse',\n",
    "            'the mouse ran away from the house',\n",
    "            'the cat finally ate the mouse',\n",
    "            'the end of the mouse story'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The house had a little tiny mouse',\n",
       " ' The cat saw the mouse',\n",
       " ' The mouse ran away from the house']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = 'The house had a little tiny mouse. The cat saw the mouse. The mouse ran away from the house'\n",
    "\n",
    "stc_split = sentence.split('.')\n",
    "\n",
    "stc_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ate', 'away', 'cat', 'end', 'finally', 'house', 'little', 'mouse', 'ran', 'saw', 'story', 'tiny']\n",
      "[0.         0.         0.         0.         0.         0.4755751\n",
      " 0.58946308 0.28088232 0.         0.         0.         0.58946308]\n",
      "[[0.         0.         0.         0.         0.         0.4755751\n",
      "  0.58946308 0.28088232 0.         0.         0.         0.58946308]\n",
      " [0.         0.         0.58873218 0.         0.         0.\n",
      "  0.         0.34771471 0.         0.72971837 0.         0.        ]\n",
      " [0.         0.58946308 0.         0.         0.         0.4755751\n",
      "  0.         0.28088232 0.58946308 0.         0.         0.        ]\n",
      " [0.58946308 0.         0.4755751  0.         0.58946308 0.\n",
      "  0.         0.28088232 0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.67009179 0.         0.\n",
      "  0.         0.31930233 0.         0.         0.67009179 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from unittest import result\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vect = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "result = vect.fit_transform(corpus)\n",
    "\n",
    "print(vect.get_feature_names())\n",
    "\n",
    "print(result.toarray()[0])\n",
    "\n",
    "print(result.todense())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1cca9558bc5ad879ec93cc030b157d75f18267527c60932cecaace349eef54dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
